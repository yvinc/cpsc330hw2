{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 2: Decision trees and machine learning fundamentals \n",
    "### Associated lectures: [Lectures 2 and 3](https://ubc-cs.github.io/cpsc330-2024W1/README.html) \n",
    "\n",
    "**Due date: See the [Calendar](https://htmlpreview.github.io/?https://github.com/UBC-CS/cpsc330/blob/master/docs/calendar.html)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "## Instructions\n",
    "rubric={points}\n",
    "\n",
    "You are welcome to broadly discuss questions with your classmates but your final answers must be your own. **We are not allowing group submission for this homework assignment.**  \n",
    "\n",
    "**Important**: In this assignment, we are using an autograder so you can receive feedback on your solutions. For the autograder to work, you need to ensure that `otter-grader` is installed in the course environment. If you successfully installed the course environment, `otter-grader` should already be included. If not, you'll need to install it explicitly.\n",
    "\n",
    "1. Go to the command line/terminal.\n",
    "2. Activate the course conda environment and install otter-grader using the following commands.\n",
    "\n",
    "    ```\n",
    "    conda activate cpsc330\n",
    "    pip install otter-grader\n",
    "    ```\n",
    "\n",
    "The cell at the top of the notebook will throw an error if you do not install `otter-grader`. Once you are done with the assignment follow the instructions below before the submission. \n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2024W1/blob/master/docs/homework_instructions.md). \n",
    "\n",
    "1. Before submitting the assignment, run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from \"1\" will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Follow the [CPSC 330 homework instructions](https://ubc-cs.github.io/cpsc330-2024W1/docs/homework_instructions.html), which include information on how to do your assignment and how to submit your assignment.\n",
    "4. Upload your solution on Gradescope. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. \n",
    "5. Make sure that the plots and output are rendered properly in your submitted file. If the .ipynb file is too big and doesn't render on Gradescope, also upload a pdf or html in addition to the .ipynb so that the TAs can view your submission on Gradescope.\n",
    "   \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "## Worksheet section\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Exercise 1: Terminology\n",
    "rubric={autograde}\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "Please fill in each of the following sentences using the provided machine learning terminologies from the list below. Keep in mind that each term should be used only once!\n",
    "\n",
    "**List of Terms (in no particular order):**\n",
    "\n",
    "    a) hyperparameters\n",
    "    b) training\n",
    "    c) tree depth\n",
    "    d) parameters\n",
    "    e) example/data point\n",
    "    f) features\n",
    "    g) target\n",
    "    h) root node\n",
    "    i) branch\n",
    "    j) leaf node\n",
    "\n",
    "    \n",
    "\n",
    "1. In the context of working with data, each individual row or instance, which includes both feature values and the corresponding target, is commonly referred to as an ________.\n",
    "\n",
    "2. In supervise machine learning, the ________ is the variable we aim to predict or understand.\n",
    "\n",
    "3. Before diving into the modeling process, it is necessary to define specific settings that impact the learning process; these settings are known as ________.\n",
    "\n",
    "4. After the model has completed the training phase, it acquires specific values, such as which features to prioritize and the threshold for splitting them in the case of decision trees; these acquired values are referred to as _________.\n",
    "   \n",
    "5. In decision trees, the initial question we ask, which serves as the starting point, is commonly referred to as the ________.\n",
    "\n",
    "6. The total number of steps or transitions from the initial question all the way to the final prediction in a decision tree is known as the ________."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# format your answer like this: terminology = ['x','x','x','x','x','x']\n",
    "terminology = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Decision trees with a toy dataset \n",
    "<hr>\n",
    "\n",
    "Suppose you have three different job offers with comparable salaries and job descriptions. You want to decide which one to accept, and you want to make this decision based on which job is likely to make you happy. Being a very systematic person, you come up with three features associated with the offers, which are important for your happiness: whether the colleagues are supportive, whether there is work-hour flexibility, and whether the company is a start-up or not. So the `X` of your offer data looks as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "offer_data = {\n",
    "    # Features\n",
    "    \"supportive_colleagues\": [1, 0, 0, 1],\n",
    "    \"work_hour_flexibility\": [0, 0, 1, 1],\n",
    "    \"start_up\": [0, 1, 1, 1],    \n",
    "}\n",
    "\n",
    "offer_df = pd.DataFrame(offer_data)\n",
    "offer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal is to get predictions for these rows. In other words, for each row, you want to predict whether that job would make you **happy** or **unhappy**.   \n",
    "\n",
    "So you ask the following questions to some of your friends (who you think have similar notions of happiness) regarding their jobs:\n",
    "\n",
    "1. Do you have supportive colleagues? (1 for 'yes' and 0 for 'no')\n",
    "2. Do you have flexible work hours? (1 for 'yes' and 0 for 'no')\n",
    "3. Do you work for a start-up? (1 for 'start up' and 0 for 'non start up')\n",
    "4. Are you happy in your job? (happy or unhappy)\n",
    "\n",
    "Suppose you get the following data from this toy survey. You decide to train a machine learning model using this toy survey data and use this model to predict which job from `offer_df` is likely to make you happy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "happiness_data = {\n",
    "    # Features\n",
    "    \"supportive_colleagues\": [1, 1, 1, 0, 0, 1, 1, 0, 1, 0],\n",
    "    \"work_hour_flexibility\": [1, 1, 0, 1, 1, 0, 1, 0, 0, 0],\n",
    "    \"start_up\": [1, 0, 1, 0, 1, 0, 0, 1, 1, 0],\n",
    "    # Target\n",
    "    \"target\": [\n",
    "        \"happy\",\n",
    "        \"happy\",\n",
    "        \"happy\",\n",
    "        \"unhappy\",\n",
    "        \"unhappy\",\n",
    "        \"happy\",\n",
    "        \"happy\",\n",
    "        \"unhappy\",\n",
    "        \"unhappy\",\n",
    "        \"unhappy\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "train_df = pd.DataFrame(happiness_data)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.1 Decision stump by hand \n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "- With this toy dataset, build a decision stump (decision tree with only 1 split) manually, splitting on the condition `supportive_colleagues <= 0.5`. What training accuracy would you get with this decision stump? Save the accuracy as a decimal in an object named `supportive_colleagues_acc`. \n",
    "\n",
    "> You do not have to show any calculations or code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "supportive_colleagues_acc = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.2 Separating features and target\n",
    "rubric={autograde}\n",
    "\n",
    "Recall that in `scikit-learn`, before building a classifier, we need to separate features and target. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Separate features and target from `train_df` and save them in `X_train_toy` and `y_train_toy`, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_toy = None\n",
    "y_train_toy = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.3 Create a decision tree classifier object\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a `DecisionTreeClassifier` object with `random_state=16` and store it in a variable called `toy_tree`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "toy_tree = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.4 `fit` the decision tree classifier \n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Now train a decision tree model by calling `fit` on `toy_tree` with `X_train_toy` and `y_train_toy` created above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.4\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.5 Visualize the trained decision tree\n",
    "rubric={autograde}\n",
    "\n",
    "\n",
    "**Your tasks:**\n",
    "- Visualize the trained decision tree model using the [`tree.plot_tree`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html) method in `sklearn` by passing the appropriate values for the following arguments: \n",
    "    - `feature_names`\n",
    "    - `class_names`\n",
    "  \n",
    "Save the names of the features in `feature_names` variable, names of the classes in `class_names` variable and the visualization tree returned by the function in a variable called `toy_tree_viz`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.5\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toy_tree_viz = None\n",
    "feature_names = [] # feature names \n",
    "class_names = [] # unique class names \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.6 Depth of the tree\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. What's the depth of the learned decision tree model? Save it as an integer in the variable `toy_depth` below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.6\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "toy_depth = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.7 Accuracy calculation\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Evaluate the `toy_tree` on the training data (i.e., call `score()` on `X_train_toy` and `y_train_toy`) and store the score in a variable called `train_acc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.7\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_acc = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.8 Discussion\n",
    "rubric={reasoning}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Do you achieve perfect training accuracy? If so, what are the reasons behind this, and if not, what factors contribute to the imperfection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.8\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.9 Predicting on the offer data \n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Using the trained decision tree above, predict the targets for all examples in `offer_df` and store them as a list in the `predictions` variable below.\n",
    "2. In which jobs you are likely to be happy? Append the index or indices of all the examples where you are likely to be happy to the 'happy_job_indices' list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "offer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.9\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "happy_job_indices = []\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "## Homework Section\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Decision trees on Spotify Song Attributes dataset \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introducing the dataset\n",
    " \n",
    "For the rest of the homework, you'll be using Kaggle's [Spotify Song Attributes](https://www.kaggle.com/geomack/spotifyclassification/home) dataset. The dataset contains a number of features of songs from 2017 and a binary variable `target` that represents whether the user liked the song (encoded as 1) or not (encoded as 0). See the documentation of all the features [here](https://developer.spotify.com/documentation/web-api/reference/get-audio-features). \n",
    "\n",
    "This dataset is publicly available on Kaggle, and you will have to download it yourself. Follow the steps below to get the data CSV. \n",
    "\n",
    "1. If you do not have an account with [Kaggle](https://www.kaggle.com/), you will first need to create one (it's free).\n",
    "2. Login to your account and [download](https://www.kaggle.com/geomack/spotifyclassification/download) the dataset.\n",
    "3. Unzip the data file if needed, then rename it to `spotify.csv`, and move it under the `data` directory.\n",
    "\n",
    "> You will not be able to push it to your repository (hopefully) because I have seeded the repository with `.gitignore`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d4d478b6cdc9bf88",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 3.1 Reading the data CSV\n",
    "rubric={autograde}\n",
    " \n",
    "**Your tasks:**\n",
    "1. Read in the data CSV and store it as a pandas dataframe named `spotify_df`. The first column of the .csv file should be set as the index.\n",
    "\n",
    "> Make sure you have put the data CSV as `spotify.csv` under the data directory (data/spotify.csv). When you read the data file, use this relative path for the autograder to work properly on Gradescope. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3.1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4f3f14b59fd7e6b8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "spotify_df = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 3.2 Data splitting \n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the dataframe into `train_df` and `test_df` with `random_state=123` and `test_size=0.2`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3.2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = None\n",
    "test_df = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 3.3 Number of training and test examples\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "1. How many training and test examples do we have? Store them as integers in the variables below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3.3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please provide integer values\n",
    "n_train_samples = None\n",
    "n_test_samples = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d4d478b6cdc9bf88",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 3.4 `describe` method \n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Store the output of `describe()` **on the training split** in `spotify_summary` variable below and display the summary statistics. By default, this function will compute some summary statistics of the numeric columns.\n",
    "\n",
    "> Note that `describe` returns another DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3.4\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "spotify_summary = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d4d478b6cdc9bf88",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 3.5 Largest range feature\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Which feature has the largest range? Store the feature name as a string in the `largest_range_feature` variable below.\n",
    "\n",
    "> Hint: You can subtract the min value from the max value of the column to get the range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3.5\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "largest_range_feature = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b33320bcf667584a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3.6 Plotting histograms \n",
    "rubric={viz}\n",
    "\n",
    "The starter code below produces histograms for the `loudness` feature using pandas plotting. The histograms show the distribution of the feature values in the training set, separated for positive (target=1, i.e., user liked the song) and negative (target=0, i.e., user disliked the song) examples. There are two different histograms, one for target = 0 and one for target = 1, and they are overlaid on top of each other. The histogram shows that extremely quiet songs tend to be disliked (more blue bars than orange on the left) and very loud songs also tend to be disliked (more blue than orange on the far right).\n",
    "\n",
    "> Note: I am using `matplotlib` and pandas plotting here. If you decide to use other visualization libraries, they might not work on Gradescope because they won't be present in the environment file on Gradescope. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "metadata": {
     "tags": [
      "otter_ignore"
     ]
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat = \"loudness\"\n",
    "train_df.groupby(\"target\")[feat].plot.hist(bins=50, alpha=0.5, legend=True, density = True, title = \"Histogram of \" + feat);\n",
    "plt.xlabel(feat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Your tasks:**\n",
    "\n",
    "Create histograms for the following features in the order below.\n",
    "- acousticness\n",
    "- danceability\n",
    "- tempo\n",
    "- energy\n",
    "- valence\n",
    "\n",
    "> To adhere to the [DRY (Don't Repeat Yourself)](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself) principle, make sure you use a `for` loop for your plotting, rather than repeating the plotting code 4 times. For this to work, I used `plt.show()` at the end of your loop, which draws the figure and resets the canvas for your next plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3.6\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "metadata": {
     "tags": [
      "otter_ignore"
     ]
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3.7 Identical histograms\n",
    "rubric={reasoning}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Let's say that, for a particular feature, the histograms of that feature are identical for the two target classes. Does that mean the feature is not useful for predicting the target class? Briefly explain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3.7\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86f9e0c649669daf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3.8 Which columns to include? \n",
    "rubric={reasoning}\n",
    "\n",
    "Note that the dataset includes two text features labeled `song_title` and `artist`.\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Do you believe that these features could be valuable in predicting whether the user liked the song or not? If so, what makes them suitable, and if not, what makes them unsuitable?\n",
    "2. Do you anticipate any challenges in using these features in their current form within your model? Please provide a brief explanation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3.8\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Exercise 4: Model building\n",
    "<hr>\n",
    "\n",
    "Now that we did some preliminary exploratory data analysis (EDA), let's move on to modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-706403e72adade4b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 4.1 Creating `X` and `y`\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Separate `X` and `y` from `train_df` and `test_df` from the previous exercise and store them as `X_train`, `y_train`, `X_test`, `y_test`, respectively. Skip the `song_title` and `artist` columns for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_4.1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = None\n",
    "y_train = None\n",
    "X_test = None\n",
    "y_test = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 4.2 The baseline model: `DummyClassifier`\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out 10-fold cross-validation using `DummyClassifier` with `random_state=123`. Store the mean cross-validation score in the `dummy_score` variable below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_4.2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_score = None\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-706403e72adade4b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 4.3 Creating a Decision Tree model\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a `DecisionTreeClassifier` with `random_state=123` and store it in a variable called `spotify_tree`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_4.3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spotify_tree = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 4.4 Cross-validation with `DecisionTreeClassifier`\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:** \n",
    "\n",
    "1. Carry out 10-fold cross validation with the `spotify_tree` object above using `cross_validate` on `X_train` and `y_train`. Pass `return_train_score=True` to `cross_validate`. Save the results as a pandas dataframe in a variable called `dt_scores_df`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_4.4\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt_scores_df = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 4.5 Examining cross-validation scores\n",
    "rubric={reasoning}\n",
    "\n",
    "**Your tasks:** \n",
    "1. Inspect the 10 sub-scores from the 10 folds of cross-validation. To what extent do you trust the numerical value / precision of the cross validation score? Briefly explain.  \n",
    "2. Do you see a significant difference between the training scores and the cross-validation scores? Briefly discuss in 1 to 2 sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_4.5\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Exercise 5: Hyperparameters\n",
    "<hr>\n",
    "\n",
    "In this exercise, you'll experiment with the `max_depth` hyperparameter of the decision tree classifier. See the [`DecisionTreeClassifier` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 5.1 Train and cross-validation accuracies \n",
    "rubric={autograde}\n",
    "\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Explore the `max_depth` hyperparameter. Run 10-fold cross-validation for trees with the following values of `max_depth`: `np.arange(1, 25, 2)`. Set the `random_state` of `DecisionTreeClassifier` to 123 in each case for reproducibility. \n",
    "2. For each `max_depth`, get both the mean train accuracy and the mean cross-validation accuracy. Store your results in the `results_df` dataframe, where the max_depth is set as the index. \n",
    "\n",
    "> Note: generally speaking (for all assignments) you are welcome to copy/paste code directly from the lecture notes, though I ask that you add a small citation (e.g. \"Adapted from lecture 1\") if you do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "depths = np.arange(1, 25, 2)\n",
    "depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_5.1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 5.2 Visualization \n",
    "rubric={viz}\n",
    "\n",
    "1. Make a plot with `max_depth` on the *x*-axis and the train and cross-validation accuracies on the *y*-axis. That is, your plot should have two curves, one for train and one for cross-validation. \n",
    "\n",
    "**Ensure your plot includes the following:**\n",
    "\n",
    "1. Both the train accuracy and the cross-validation accuracy are included in the plot.\n",
    "2. Include a legend to specify which is which. \n",
    "3. The provided `max_depth` values are used.\n",
    "4. The x-axis and y-axis have reasonable names.\n",
    "5. The data points are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_5.2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 5.3 `max_depth` and the fundamental tradeoff\n",
    "rubric={reasoning}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Discuss how changing the `max_depth` hyperparameter affects the training and cross-validation accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_5.3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 5.4 Picking the \"best\" value for `max_depth`\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "1. From these results, pick the \"best\" `max_depth`, the one which gives the maximum cross-validation score. Store it in a variable called `best_max_depth` as an integer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_5.4\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_max_depth = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Final assessment\n",
    "<hr>\n",
    "\n",
    "Now that we have our finalized model, we are ready to evaluate it on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 6.1 Final assessment on the test split \n",
    "rubric={autograde}\n",
    "\n",
    "\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a decision tree model `best_model` using the `best_max_depth` you chose in the previous exercise with `random_state=123`. \n",
    "2. Fit the `best_model` on the _entire training set_ (`X_train` and `y_train`). \n",
    "2. Compute the test score (on `X_test` and `y_test`) and store it in a variable called `test_score` below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_6.1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = None\n",
    "test_score = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 6.2 Analysis\n",
    "rubric={reasoning}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. How do the test scores compare to the cross-validation scores? Briefly discuss. \n",
    "2. Why can't you simply pick the value of `max_depth` that gives the best accuracy on the training data? (Answer in maximum 2 to 3 sentences.)\n",
    "3. Do you think that the `max_depth` you chose would generalize to other \"spotify\" datasets (i.e., data on other spotify users)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_6.2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before submitting your assignment, please make sure you have followed all the instructions in the Submission Instructions section at the top. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Congratulations on working with your first machine learning model! Well done 👏👏!\n",
    "\n",
    "![](img/eva-well-done.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1.1": {
     "name": "q1.1",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(terminology) == 6, 'Please answer all the 6 questions.'\n>>> assert sha1(''.join(terminology).encode('utf-8').lower()).hexdigest() == '697caf6e863b577f985abae3c4cc95db6e46feda', 'Your answers do not match the expected solution. Please try again.'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.1": {
     "name": "q2.1",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not supportive_colleagues_acc is None, 'Are you setting the provided variable?'\n>>> assert sha1(str(supportive_colleagues_acc).encode('utf8')).hexdigest() == '1469842b4307d36cccb487dc989f21016daadbcc', 'Your answer is incorrect, see traceback above.'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.2": {
     "name": "q2.2",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not X_train_toy is None, 'Are you using the correct variable?'\n>>> assert not y_train_toy is None, 'Are you using the correct variable?'\n>>> assert X_train_toy.shape == (10, 3), 'X_train_toy shape is incorrect'\n>>> assert y_train_toy.shape == (10,), 'y_train_toy shape is incorrect'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.3": {
     "name": "q2.3",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(toy_tree, DecisionTreeClassifier), 'DecisionTreeClassifier was not created properly'\n>>> assert toy_tree.get_params().get('random_state') == 16, 'Please set the random state to 16'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.4": {
     "name": "q2.4",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert toy_tree.get_depth() in range(2, 4, 1), 'DecisionTreeClassifier was not fitted properly'\n>>> assert toy_tree.get_n_leaves() in range(3, 5, 1), 'DecisionTreeClassifier was not fitted properly'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.5": {
     "name": "q2.5",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not toy_tree_viz is None, 'Are you using the provided variable?'\n>>> assert sha1(str(len(feature_names)).encode('utf-8')).hexdigest() == '77de68daecd823babbb58edb1c8e14d7106e83bb', 'Are you passing the correct list of features?'\n>>> assert sha1(str(sorted(list(class_names))).encode('utf-8')).hexdigest() == '4621a7584156c08258ad22a7adc86667984d9382', 'Are you passing the correct list of classes?'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.6": {
     "name": "q2.6",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not toy_depth is None, 'Are you using the provided variable?'\n>>> assert sha1(str(toy_depth).encode('utf-8')).hexdigest() == '77de68daecd823babbb58edb1c8e14d7106e83bb', 'The depth is incorrect'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.7": {
     "name": "q2.7",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not train_acc is None, 'Are you using the provided train_acc variable?'\n>>> assert sha1(str(np.round(train_acc, 2)).encode('utf-8')).hexdigest() == '1469842b4307d36cccb487dc989f21016daadbcc', 'The score is incorrect'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.9": {
     "name": "q2.9",
     "points": [
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not predictions is None, 'Are you storing predictions in the provided variable predictions?'\n>>> assert predictions.count('happy') == 2, 'Your predictions do not look as expected.'\n>>> assert predictions.count('unhappy') == 2, 'Your predictions do not look as expected.'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not happy_job_indices is None, 'Are you storing the happy job indices in the provided variable?'\n>>> assert len(happy_job_indices) == 2, 'The length of happy_job_indices list seems wrong. '\n>>> assert sha1(str(sorted(happy_job_indices)).encode('utf-8')).hexdigest() == 'c48ac7e6c9a92c1a4160e3096f915d1651e6c18f', 'The happy job indices do not look correct.'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.1": {
     "name": "q3.1",
     "points": [
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(spotify_df, pd.DataFrame), 'The DataFrame is not loaded correctly'\n>>> assert spotify_df.shape == (2017, 16), 'The DcataFrame has the wrong shape'\n>>> assert np.isclose(spotify_df.valence.sum(), 1002.08), 'The DataFrame is not loaded correctly'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not spotify_df.columns[0] != 'acousticness', \"Perhaps you haven't set the first column as an index column\"\n>>> assert spotify_df.index.dtype == 'int64', 'Your index dtype is incorrect'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.2": {
     "name": "q3.2",
     "points": [
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not train_df is None and (not test_df is None), 'Are you using the provided variables?'\n>>> n_total_samples = spotify_df.shape[0]\n>>> assert test_df.shape[0] == round(n_total_samples * 0.2) + (n_total_samples % 5 > 0), 'Are you using the provided test size?'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(train_df.iloc[30]['liveness'], 0.268), 'Are you using the provided random state?'\n>>> assert np.isclose(test_df.iloc[88]['danceability'], 0.727), 'Are you using the provided random state?'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.3": {
     "name": "q3.3",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not n_train_samples is None, 'n_train_samples not set'\n>>> assert not n_test_samples is None, 'n_test_samples not set.'\n>>> assert sha1(str(n_train_samples).encode('utf8')).hexdigest() == '2a7bcf3804dc71895222bdd5f95e64444ce51654', 'n_train_samples is not set correctly.'\n>>> assert sha1(str(n_test_samples).encode('utf8')).hexdigest() == 'c35a9fc52bb556c79f8fa540df587a2bf465b940', 'n_test_samples is not set correctly.'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.4": {
     "name": "q3.4",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(spotify_summary, pd.DataFrame), 'Are you storing the dataframe in spotify_summary?'\n>>> assert spotify_summary.shape == (8, 14), 'Please call describe'\n>>> assert np.isclose(round(spotify_summary.iloc[2]['energy'], 3), 0.212), 'Please call describe'\n>>> assert [round(x, 2) for x in sorted(list(spotify_summary['mode']))] == [0.0, 0.0, 0.49, 0.62, 1.0, 1.0, 1.0, 1613.0], 'Please call describe'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.5": {
     "name": "q3.5",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not largest_range_feature is None, 'Are you using the provided variable?'\n>>> assert sha1(str(largest_range_feature.lower()).encode('utf8')).hexdigest() == 'b2b3efacda1eba27a1e3780616a92b9563c33a59', 'Please use the exact column/feature name'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4.1": {
     "name": "q4.1",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(X_train, pd.DataFrame), 'X_train is not created correctly'\n>>> assert isinstance(y_train, pd.Series), 'y_train is not created correctly'\n>>> assert isinstance(X_test, pd.DataFrame), 'X_test is not created correctly'\n>>> assert isinstance(y_test, pd.Series), 'y_test is not created correctly'\n>>> assert X_train.shape == (1613, 13), 'X_train has the wrong shape'\n>>> assert X_test.shape == (404, 13), 'X_test has the wrong shape'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4.2": {
     "name": "q4.2",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not dummy_score is None, 'Are you using the provided variable?'\n>>> assert sha1(str(round(dummy_score, 3)).encode('utf8')).hexdigest() == '18c726bc32625cbbb170d7b4127af31fae7c6270', 'DummyClassifier score seems incorrect'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4.3": {
     "name": "q4.3",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(spotify_tree, DecisionTreeClassifier), 'DecisionTreeClassifier was not created properly'\n>>> assert spotify_tree.get_params().get('random_state') == 123, 'Please set the random state to 123'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4.4": {
     "name": "q4.4",
     "points": [
      1,
      1,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(dt_scores_df, pd.DataFrame), 'dt_scores_df should be a DataFrame'\n>>> assert len(dt_scores_df) == 10, 'Please check parameters of `cross_validate`'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert dt_scores_df.shape[0] == 10, 'Are you carrying out 10-fold cross-validation?'\n>>> assert dt_scores_df.shape[1] == 4, 'Are you passing return_train_scores = True?'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(round(dt_scores_df['test_score'].mean(), 3), 0.671), 'Your test scores are incorrect'\n>>> assert np.isclose(round(dt_scores_df['train_score'].mean(), 3), 0.999), 'Your train scores are incorrect'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5.1": {
     "name": "q5.1",
     "points": 6,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert X_train.shape == (1613, 13), 'Shape is incorrect'\n>>> assert y_train.shape == (1613,), 'Shape is incorrect'\n>>> assert X_test.shape == (404, 13), 'Shape is incorrect'\n>>> assert y_test.shape == (404,), 'Shape is incorrect'\n>>> assert round(X_train.iloc[123]['loudness'], 2) == -10.1, 'Are you using the correct X_train, y_train, X_test, y_test?'\n>>> assert round(y_train.iloc[62], 2) == 0.0, 'Are you using the correct X_train, y_train, X_test, y_test?'\n>>> assert round(X_test.iloc[234]['valence'], 2) == 0.18, 'Are you using the correct X_train, y_train, X_test, y_test?'\n>>> assert round(y_test.iloc[399], 2) == 1.0, 'Are you using the correct X_train, y_train, X_test, y_test?'\n>>> assert results_df.shape[0] == 12, 'Are you creating results_df correctly?'\n>>> assert results_df.shape[1] in [2, 3], 'Are you creating results_df correctly?'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5.4": {
     "name": "q5.4",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not best_max_depth is None, 'Are you using the provided variable?'\n>>> assert sha1(str(best_max_depth).encode('utf-8')).hexdigest() == 'ac3478d69a3c81fa62e60f5c3696165a4e5e6ac4', 'Are you picking the best_max_depth which gives the highest cross-validation score?'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6.1": {
     "name": "q6.1",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "01a99afb195f98bb02f5f6140981f0a7ac9be086d08c6d08f7c825fb9196b5aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
